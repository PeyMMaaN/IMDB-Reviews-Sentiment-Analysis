{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearning.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3TLUlkWRnAV",
        "colab_type": "code",
        "outputId": "45ff6e00-bfa1-437f-a790-27728007e9b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from PreProcessing import TextCleaner\n",
        "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.python.keras.layers import Embedding, Bidirectional, LSTM, Flatten\n",
        "from tensorflow.python.keras.layers import Convolution1D, GlobalMaxPool1D, Dense, Dropout\n",
        "from tensorflow.python.keras.models import Model, Sequential\n",
        "\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "from keras import backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cg22fxPpWPlf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5017f4ec-6f0a-4083-deb4-55f6757921ed"
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/IMDB Reviews Sentiment Analysis/IMDB-Reviews.csv', encoding='utf-8')\n",
        "\n",
        "df = df.dropna(axis=0) # remove reviews which contains NaN value\n",
        "df = df.drop_duplicates() # remove repeated rows from training data. now df has just unique reviews.\n",
        "\n",
        "reviews = list(df['review']) # make reviews exclusive\n",
        "\n",
        "# clean each review based on TextCleaner\n",
        "cleaner = TextCleaner()\n",
        "for indx, text in enumerate(tqdm(reviews)):\n",
        "    reviews[indx] = cleaner.clean_text(text)\n",
        "\n",
        "df['review']    = reviews # replace clean reviews with column of reviews in dataframe\n",
        "df['sentiment'] = df['sentiment'].map({'negative': 0, 'positive': 1}) # encode posetive & negative"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 49582/49582 [01:27<00:00, 566.69it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVPT4hGm92AE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4d8f5bcf-f0f7-4441-e891-3ca9d6f7bf87"
      },
      "source": [
        "print('Maximum number of features that a sentence has: ' + str(df.review.map(len).max()))\n",
        "print('the mean of the length of sentences is: ' + str(df.review.apply(lambda x: len(x.split(\" \"))).mean()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Maximum number of features that a sentence has: 8761\n",
            "the mean of the length of sentences is: 122.07668105360817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlUrc-tmAl-p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_maxFeatures = 6500  # less than 8761\n",
        "num_maxLen = 130 # more than 122.07\n",
        "embed_size = 123 # nearly to 122.07\n",
        "\n",
        "tokenizer = Tokenizer(num_words=num_maxFeatures)\n",
        "tokenizer.fit_on_texts(df['review'])\n",
        "training_data = tokenizer.texts_to_sequences(df['review'])\n",
        "\n",
        "X_train = pad_sequences(training_data, maxlen=num_maxLen)\n",
        "Y_train = df['sentiment']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OYYjQQ87oM8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define our Gussian Error Linear Unit Activation Function\n",
        "def gelu(x):\n",
        "    return 1 + K.tanh(0.798086 * (x + K.pow(x, 3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IN20Z200DGpZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Embedding(input_dim=num_maxFeatures, output_dim=embed_size))\n",
        "\n",
        "    model.add(Convolution1D(128, kernel_size=5, padding='valid', activation=gelu, strides=1))\n",
        "    model.add(Dropout(rate=0.5))\n",
        "\n",
        "    model.add(Bidirectional(LSTM(32, return_sequences=True)))\n",
        "    \n",
        "    model.add(GlobalMaxPool1D())\n",
        "\n",
        "    model.add(Dense(20, activation=gelu))\n",
        "    model.add(Dropout(rate=0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BVNt_MnIoK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izU9w_ONItpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "e4da729a-aa9f-4d20-d698-d219a6a5182e"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 123)         799500    \n",
            "_________________________________________________________________\n",
            "conv1d (Conv1D)              (None, None, 128)         78848     \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, None, 64)          41216     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 20)                1300      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 21        \n",
            "=================================================================\n",
            "Total params: 920,885\n",
            "Trainable params: 920,885\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ8IhQGoJvxm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = 'model.hdf5'\n",
        "mcp = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_Gzr1DUqAK-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "87823b8f-38dc-4a7a-deaa-24ae3420f1dc"
      },
      "source": [
        "history = model.fit(X_train, Y_train, batch_size=100, epochs=6, validation_split=0.2, callbacks=[mcp])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/6\n",
            "397/397 [==============================] - ETA: 0s - loss: 0.6225 - accuracy: 0.6209\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.83120, saving model to model.hdf5\n",
            "397/397 [==============================] - 607s 2s/step - loss: 0.6225 - accuracy: 0.6209 - val_loss: 0.3840 - val_accuracy: 0.8312\n",
            "Epoch 2/6\n",
            "397/397 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8683\n",
            "Epoch 00002: val_accuracy improved from 0.83120 to 0.86337, saving model to model.hdf5\n",
            "397/397 [==============================] - 602s 2s/step - loss: 0.3302 - accuracy: 0.8683 - val_loss: 0.3173 - val_accuracy: 0.8634\n",
            "Epoch 3/6\n",
            "397/397 [==============================] - ETA: 0s - loss: 0.2674 - accuracy: 0.8992\n",
            "Epoch 00003: val_accuracy improved from 0.86337 to 0.87658, saving model to model.hdf5\n",
            "397/397 [==============================] - 599s 2s/step - loss: 0.2674 - accuracy: 0.8992 - val_loss: 0.2891 - val_accuracy: 0.8766\n",
            "Epoch 4/6\n",
            "397/397 [==============================] - ETA: 0s - loss: 0.2345 - accuracy: 0.9146\n",
            "Epoch 00004: val_accuracy improved from 0.87658 to 0.87930, saving model to model.hdf5\n",
            "397/397 [==============================] - 609s 2s/step - loss: 0.2345 - accuracy: 0.9146 - val_loss: 0.2919 - val_accuracy: 0.8793\n",
            "Epoch 5/6\n",
            "397/397 [==============================] - ETA: 0s - loss: 0.2125 - accuracy: 0.9234\n",
            "Epoch 00005: val_accuracy did not improve from 0.87930\n",
            "397/397 [==============================] - 600s 2s/step - loss: 0.2125 - accuracy: 0.9234 - val_loss: 0.3089 - val_accuracy: 0.8761\n",
            "Epoch 6/6\n",
            "397/397 [==============================] - ETA: 0s - loss: 0.1890 - accuracy: 0.9340\n",
            "Epoch 00006: val_accuracy improved from 0.87930 to 0.88061, saving model to model.hdf5\n",
            "397/397 [==============================] - 588s 1s/step - loss: 0.1890 - accuracy: 0.9340 - val_loss: 0.3072 - val_accuracy: 0.8806\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q5t44Oc-WOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}